{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting game_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%file game_agent.py\n",
    "\n",
    "\"\"\"This file contains all the classes you must complete for this project.\n",
    "\n",
    "You can use the test cases in agent_test.py to help during development, and\n",
    "augment the test suite with your own test cases to further test your code.\n",
    "\n",
    "You must test your agent's strength against a set of agents with known\n",
    "relative strength using tournament.py and include the results in your report.\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "\n",
    "class Timeout(Exception):\n",
    "    \"\"\"Subclass base exception for code clarity.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def custom_score(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "\n",
    "    return heuristic_score_weighted_with_board(game, player)\n",
    "\n",
    "def heuristic_score_simple(game, player):\n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves - opp_moves)\n",
    "\n",
    "def heuristic_score_weighted(game, player):\n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves * 2 - opp_moves * 1)\n",
    "\n",
    "def heuristic_score_weighted_with_board(game, player):\n",
    "    blank_spaces = len(game.get_blank_spaces())\n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves * 3 - opp_moves * 2 + blank_spaces * 1)\n",
    "\n",
    "class CustomPlayer:\n",
    "    \"\"\"Game-playing agent that chooses a move using your evaluation function\n",
    "    and a depth-limited minimax algorithm with alpha-beta pruning. You must\n",
    "    finish and test this player to make sure it properly uses minimax and\n",
    "    alpha-beta to return a good move before the search time limit expires.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_depth : int (optional)\n",
    "        A strictly positive integer (i.e., 1, 2, 3,...) for the number of\n",
    "        layers in the game tree to explore for fixed-depth search. (i.e., a\n",
    "        depth of one (1) would only explore the immediate sucessors of the\n",
    "        current state.)\n",
    "\n",
    "    score_fn : callable (optional)\n",
    "        A function to use for heuristic evaluation of game states.\n",
    "\n",
    "    iterative : boolean (optional)\n",
    "        Flag indicating whether to perform fixed-depth search (False) or\n",
    "        iterative deepening search (True).\n",
    "\n",
    "    method : {'minimax', 'alphabeta'} (optional)\n",
    "        The name of the search method to use in get_move().\n",
    "\n",
    "    timeout : float (optional)\n",
    "        Time remaining (in milliseconds) when search is aborted. Should be a\n",
    "        positive value large enough to allow the function to return before the\n",
    "        timer expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_depth=3, score_fn=custom_score,\n",
    "                 iterative=True, method='minimax', timeout=10.):\n",
    "        self.search_depth = search_depth\n",
    "        self.iterative = iterative\n",
    "        self.score = score_fn\n",
    "        self.method = method\n",
    "        self.time_left = None\n",
    "        self.TIMER_THRESHOLD = timeout\n",
    "        self.POS_INF = float(\"inf\")\n",
    "        self.NEG_INF = float(\"-inf\")\n",
    "        self.suicide_move = (-1, -1)\n",
    "    \n",
    "    def get_move(self, game, legal_moves, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "\n",
    "        This function must perform iterative deepening if self.iterative=True,\n",
    "        and it must use the search method (minimax or alphabeta) corresponding\n",
    "        to the self.method value.\n",
    "\n",
    "        **********************************************************************\n",
    "        NOTE: If time_left < 0 when this function returns, the agent will\n",
    "              forfeit the game due to timeout. You must return _before_ the\n",
    "              timer reaches 0.\n",
    "        **********************************************************************\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "\n",
    "        legal_moves : list<(int, int)>\n",
    "            A list containing legal moves. Moves are encoded as tuples of pairs\n",
    "            of ints defining the next (row, col) for the agent to occupy.\n",
    "\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "\n",
    "        self.time_left = time_left\n",
    "\n",
    "        # TODO: finish this function!\n",
    "\n",
    "        # Perform any required initializations, including selecting an initial\n",
    "        # move from the game board (i.e., an opening book), or returning\n",
    "        # immediately if there are no legal moves\n",
    "        if not legal_moves: \n",
    "            return self.suicide_move\n",
    "\n",
    "        best_move = legal_moves[random.randint(0, len(legal_moves) - 1)]\n",
    "        best_score = self.NEG_INF\n",
    "\n",
    "        try:\n",
    "            # The search method call (alpha beta or minimax) should happen in\n",
    "            # here in order to avoid timeout. The try/except block will\n",
    "            # automatically catch the exception raised by the search method\n",
    "            # when the timer gets close to expiring\n",
    "            if self.method is 'minimax':\n",
    "                search = self.minimax\n",
    "            else:\n",
    "                search = self.alphabeta\n",
    "\n",
    "            if self.iterative:\n",
    "                search_depth = 1\n",
    "                #try as 1\n",
    "                while 1:\n",
    "                    score, next_move = search(game, depth=search_depth, maximizing_player=True)\n",
    "                    if (score, next_move) > (best_score, best_move):\n",
    "                        (best_score, best_move) = (score, next_move)\n",
    "\n",
    "                    search_depth += 1\n",
    "            else:\n",
    "                score, next_move = search(game, self.search_depth)\n",
    "\n",
    "                if (score, next_move) > (best_score, best_move):\n",
    "                    (best_score, best_move) = (score, next_move)\n",
    "\n",
    "        except Timeout:\n",
    "            # Handle any actions required at timeout, if necessary\n",
    "            return best_move\n",
    "\n",
    "        return best_move\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "\n",
    "    def minimax(self, game, depth, maximizing_player=True):\n",
    "        \"\"\"Implement the minimax search algorithm as described in the lectures.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "\n",
    "        maximizing_player : bool\n",
    "            Flag indicating whether the current search depth corresponds to a\n",
    "            maximizing layer (True) or a minimizing layer (False)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The score for the current search branch\n",
    "\n",
    "        tuple(int, int)\n",
    "            The best move for the current branch; (-1, -1) for no legal moves\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project unit tests; you cannot call any other\n",
    "                evaluation function directly.\n",
    "        \"\"\"\n",
    "        best_move = self.suicide_move\n",
    "        best_score = self.NEG_INF if maximizing_player else self.POS_INF\n",
    "        optimizer = max if maximizing_player else min\n",
    "        \n",
    "        if self.time_left() < self.TIMER_THRESHOLD: raise Timeout()\n",
    "        if depth is 0: return self.score(game, self), best_move\n",
    "        \n",
    "        for move in game.get_legal_moves():\n",
    "            score, _ = self.minimax(game.forecast_move(move), depth - 1, not maximizing_player)\n",
    "            best_score, best_move = optimizer((best_score, best_move), (score, move))\n",
    "            \n",
    "        return best_score, best_move\n",
    "    \n",
    "    \n",
    "    def alphabeta(self, game, depth, alpha=float(\"-inf\"), beta=float(\"inf\"), maximizing_player=True):\n",
    "        \"\"\"Implement minimax search with alpha-beta pruning as described in the\n",
    "        lectures.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "\n",
    "        alpha : float\n",
    "            Alpha limits the lower bound of search on minimizing layers\n",
    "\n",
    "        beta : float\n",
    "            Beta limits the upper bound of search on maximizing layers\n",
    "\n",
    "        maximizing_player : bool\n",
    "            Flag indicating whether the current search depth corresponds to a\n",
    "            maximizing layer (True) or a minimizing layer (False)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The score for the current search branch\n",
    "\n",
    "        tuple(int, int)\n",
    "            The best move for the current branch; (-1, -1) for no legal moves\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project unit tests; you cannot call any other\n",
    "                evaluation function directly.\n",
    "        \"\"\"\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise Timeout()\n",
    "            \n",
    "        best_move = self.suicide_move\n",
    "        best_score = alpha if maximizing_player else beta\n",
    "        \n",
    "        if self.time_left() < self.TIMER_THRESHOLD: raise Timeout()\n",
    "        if depth is 0: return self.score(game, self), best_move\n",
    "        \n",
    "        if maximizing_player:\n",
    "            for move in game.get_legal_moves():\n",
    "                score, _ = self.alphabeta(game.forecast_move(move), depth - 1, best_score, beta, not maximizing_player)\n",
    "                if score > best_score: \n",
    "                    best_score, best_move = score, move\n",
    "                if best_score >= beta: \n",
    "                    return (best_score, best_move)\n",
    "        else:\n",
    "            # Iterate through all possible legale moves\n",
    "            for move in game.get_legal_moves():\n",
    "                # Return the score for that \n",
    "                score, _ = self.alphabeta(game.forecast_move(move), depth - 1, alpha, best_score, not maximizing_player)\n",
    "                if score < best_score: \n",
    "                    best_score, best_move = score, move\n",
    "                if best_score <= alpha: \n",
    "                    return (best_score, best_move)\n",
    "                \n",
    "        return best_score, best_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 8.219s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run ./agent_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom heuristic function by\n",
      "comparing the strength of an agent using iterative deepening (ID) search with\n",
      "alpha-beta pruning against the strength rating of agents using other heuristic\n",
      "functions.  The `ID_Improved` agent provides a baseline by measuring the\n",
      "performance of a basic agent using Iterative Deepening and the \"improved\"\n",
      "heuristic (from lecture) on your hardware.  The `Student` agent then measures\n",
      "the performance of Iterative Deepening and the custom heuristic against the\n",
      "same opponents.\n",
      "\n",
      "\n",
      "*************************\n",
      " Evaluating: ID_Improved \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1: ID_Improved vs   Random    \tResult: 19 to 1\n",
      "  Match 2: ID_Improved vs   MM_Null   \tResult: 16 to 4\n",
      "  Match 3: ID_Improved vs   MM_Open   \tResult: 17 to 3\n",
      "  Match 4: ID_Improved vs MM_Improved \tResult: 15 to 5\n",
      "  Match 5: ID_Improved vs   AB_Null   \tResult: 18 to 2\n",
      "  Match 6: ID_Improved vs   AB_Open   \tResult: 14 to 6\n",
      "  Match 7: ID_Improved vs AB_Improved \tResult: 11 to 9\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "ID_Improved         78.57%\n",
      "\n",
      "*************************\n",
      "   Evaluating: Student   \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1:   Student   vs   Random    \tResult: 18 to 2\n",
      "  Match 2:   Student   vs   MM_Null   \tResult: 17 to 3\n",
      "  Match 3:   Student   vs   MM_Open   "
     ]
    }
   ],
   "source": [
    "#changed from False to True, and switch around assignments\n",
    "%run ./tournament.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom heuristic function by\n",
      "comparing the strength of an agent using iterative deepening (ID) search with\n",
      "alpha-beta pruning against the strength rating of agents using other heuristic\n",
      "functions.  The `ID_Improved` agent provides a baseline by measuring the\n",
      "performance of a basic agent using Iterative Deepening and the \"improved\"\n",
      "heuristic (from lecture) on your hardware.  The `Student` agent then measures\n",
      "the performance of Iterative Deepening and the custom heuristic against the\n",
      "same opponents.\n",
      "\n",
      "\n",
      "*************************\n",
      " Evaluating: ID_Improved \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1: ID_Improved vs   Random    \tResult: 8 to 12\n",
      "  Match 2: ID_Improved vs   MM_Null   \tResult: 9 to 11\n",
      "  Match 3: ID_Improved vs   MM_Open   \tResult: 9 to 11\n",
      "  Match 4: ID_Improved vs MM_Improved \tResult: 10 to 10\n",
      "  Match 5: ID_Improved vs   AB_Null   \tResult: 9 to 11\n",
      "  Match 6: ID_Improved vs   AB_Open   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/tournament.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/tournament.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_agents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmm_agents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mab_agents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magentUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mwin_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_MATCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nResults:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/tournament.py\u001b[0m in \u001b[0;36mplay_round\u001b[0;34m(agents, num_matches)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mscore_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/tournament.py\u001b[0m in \u001b[0;36mplay_match\u001b[0;34m(player1, player2)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# play both games and tally the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mwinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIME_LIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplayer1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mwinner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/isolation/isolation.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, time_limit)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mmove_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_time_millis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurr_time_millis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmove_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mcurr_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_player\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_player_moves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mmove_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36mget_move\u001b[0;34m(self, game, legal_moves, time_left)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m#try as 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;31m# Return the score for that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;31m# Return the score for that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;31m# Return the score for that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/game_agent.py\u001b[0m in \u001b[0;36malphabeta\u001b[0;34m(self, game, depth, alpha, beta, maximizing_player)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaximizing_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/isolation/isolation.py\u001b[0m in \u001b[0;36mforecast_move\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mboard\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mmove\u001b[0m \u001b[0mapplied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mnew_board\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_board\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/isolation/isolation.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;34m\"\"\" Return a deep copy of the current board. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mnew_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__player_1__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__player_2__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mnew_board\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mnew_board\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__active_player__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__active_player__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/isolation/isolation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, player_1, player_2, width, height)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__active_player__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inactive_player__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__board_state__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLANK\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__last_player_move__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mplayer_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_MOVED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_MOVED\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__player_symbols__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLANK\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmoskalyk/Projects/AIND/2_week/AIND-Isolation/isolation/isolation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__active_player__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inactive_player__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__board_state__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLANK\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__last_player_move__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mplayer_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_MOVED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_MOVED\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__player_symbols__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLANK\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#changed from False to True\n",
    "%run ./tournament.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom heuristic function by\n",
      "comparing the strength of an agent using iterative deepening (ID) search with\n",
      "alpha-beta pruning against the strength rating of agents using other heuristic\n",
      "functions.  The `ID_Improved` agent provides a baseline by measuring the\n",
      "performance of a basic agent using Iterative Deepening and the \"improved\"\n",
      "heuristic (from lecture) on your hardware.  The `Student` agent then measures\n",
      "the performance of Iterative Deepening and the custom heuristic against the\n",
      "same opponents.\n",
      "\n",
      "\n",
      "*************************\n",
      " Evaluating: ID_Improved \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1: ID_Improved vs   Random    \tResult: 10 to 10\n",
      "  Match 2: ID_Improved vs   MM_Null   \tResult: 12 to 8\n",
      "  Match 3: ID_Improved vs   MM_Open   \tResult: 9 to 11\n",
      "  Match 4: ID_Improved vs MM_Improved \tResult: 15 to 5\n",
      "  Match 5: ID_Improved vs   AB_Null   \tResult: 11 to 9\n",
      "  Match 6: ID_Improved vs   AB_Open   \tResult: 5 to 15\n",
      "  Match 7: ID_Improved vs AB_Improved \tResult: 8 to 12\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "ID_Improved         50.00%\n",
      "\n",
      "*************************\n",
      "   Evaluating: Student   \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1:   Student   vs   Random    \tResult: 11 to 9\n",
      "  Match 2:   Student   vs   MM_Null   \tResult: 14 to 6\n",
      "  Match 3:   Student   vs   MM_Open   \tResult: 12 to 8\n",
      "  Match 4:   Student   vs MM_Improved \tResult: 13 to 7\n",
      "  Match 5:   Student   vs   AB_Null   \tResult: 10 to 10\n",
      "  Match 6:   Student   vs   AB_Open   \tResult: 10 to 10\n",
      "  Match 7:   Student   vs AB_Improved \tResult: 6 to 14\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "Student             54.29%\n"
     ]
    }
   ],
   "source": [
    "#changed params and used weighted with board\n",
    "%run ./tournament.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom heuristic function by\n",
      "comparing the strength of an agent using iterative deepening (ID) search with\n",
      "alpha-beta pruning against the strength rating of agents using other heuristic\n",
      "functions.  The `ID_Improved` agent provides a baseline by measuring the\n",
      "performance of a basic agent using Iterative Deepening and the \"improved\"\n",
      "heuristic (from lecture) on your hardware.  The `Student` agent then measures\n",
      "the performance of Iterative Deepening and the custom heuristic against the\n",
      "same opponents.\n",
      "\n",
      "\n",
      "*************************\n",
      " Evaluating: ID_Improved \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1: ID_Improved vs   Random    \tResult: 9 to 11\n",
      "  Match 2: ID_Improved vs   MM_Null   \tResult: 6 to 14\n",
      "  Match 3: ID_Improved vs   MM_Open   \tResult: 9 to 11\n",
      "  Match 4: ID_Improved vs MM_Improved \tResult: 7 to 13\n",
      "  Match 5: ID_Improved vs   AB_Null   \tResult: 9 to 11\n",
      "  Match 6: ID_Improved vs   AB_Open   \tResult: 7 to 13\n",
      "  Match 7: ID_Improved vs AB_Improved \tResult: 8 to 12\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "ID_Improved         39.29%\n",
      "\n",
      "*************************\n",
      "   Evaluating: Student   \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1:   Student   vs   Random    \tResult: 11 to 9\n",
      "  Match 2:   Student   vs   MM_Null   \tResult: 10 to 10\n",
      "  Match 3:   Student   vs   MM_Open   \tResult: 11 to 9\n",
      "  Match 4:   Student   vs MM_Improved \tResult: 11 to 9\n",
      "  Match 5:   Student   vs   AB_Null   \tResult: 9 to 11\n",
      "  Match 6:   Student   vs   AB_Open   \tResult: 11 to 9\n",
      "  Match 7:   Student   vs AB_Improved \tResult: 9 to 11\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "Student             51.43%\n"
     ]
    }
   ],
   "source": [
    "%run ./tournament.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom heuristic function by\n",
      "comparing the strength of an agent using iterative deepening (ID) search with\n",
      "alpha-beta pruning against the strength rating of agents using other heuristic\n",
      "functions.  The `ID_Improved` agent provides a baseline by measuring the\n",
      "performance of a basic agent using Iterative Deepening and the \"improved\"\n",
      "heuristic (from lecture) on your hardware.  The `Student` agent then measures\n",
      "the performance of Iterative Deepening and the custom heuristic against the\n",
      "same opponents.\n",
      "\n",
      "\n",
      "*************************\n",
      " Evaluating: ID_Improved \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1: ID_Improved vs   Random    \tResult: 12 to 8\n",
      "  Match 2: ID_Improved vs   MM_Null   \tResult: 12 to 8\n",
      "  Match 3: ID_Improved vs   MM_Open   \tResult: 6 to 14\n",
      "  Match 4: ID_Improved vs MM_Improved \tResult: 8 to 12\n",
      "  Match 5: ID_Improved vs   AB_Null   \tResult: 6 to 14\n",
      "  Match 6: ID_Improved vs   AB_Open   \tResult: 13 to 7\n",
      "  Match 7: ID_Improved vs AB_Improved \tResult: 7 to 13\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "ID_Improved         45.71%\n",
      "\n",
      "*************************\n",
      "   Evaluating: Student   \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1:   Student   vs   Random    \tResult: 13 to 7\n",
      "  Match 2:   Student   vs   MM_Null   \tResult: 7 to 13\n",
      "  Match 3:   Student   vs   MM_Open   \tResult: 11 to 9\n",
      "  Match 4:   Student   vs MM_Improved \tResult: 14 to 6\n",
      "  Match 5:   Student   vs   AB_Null   \tResult: 8 to 12\n",
      "  Match 6:   Student   vs   AB_Open   \tResult: 11 to 9\n",
      "  Match 7:   Student   vs AB_Improved \tResult: 10 to 10\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "Student             52.86%\n"
     ]
    }
   ],
   "source": [
    "%run ./tournament.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
